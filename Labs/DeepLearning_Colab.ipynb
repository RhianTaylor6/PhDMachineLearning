{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0zYsanApFT6"
   },
   "source": [
    "# Deep learning with Colab\n",
    "\n",
    "We can use colab to run slightly different looking Jupyter notebooks, with access to GPUs and TPUs for training deep neural networks. The notebook can be saved to your Google Drive as a standard Jupyter notebook.\n",
    "\n",
    "First, configure the notebook to run tensorflow on a GPU. Click on the 'Runtime' heading in the menu at the top of the page, and choose 'Change runtime type'. Then select 'GPU' as the hardware accelerator. *Note if you change the hardware accelerator later, your notebook will be reset!*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a65EycH-sLam"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
    "from tensorflow.keras.regularizers import l1,l2\n",
    "from tensorflow.keras.utils import to_categorical, normalize\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ko0MMRbjp6o1"
   },
   "source": [
    "## CIFAR 10 data\n",
    "\n",
    "We will use the CIFAR10 data set provided with Keras. It contains a set of small images of 10 different types of object, with labels. You can read more about it here: http://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-CYeDm1sPn9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4a9772a6644c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fPl4Sq6EqAe1"
   },
   "source": [
    "Use the shape attribute to show the dimensions of the x_train and y_train arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-eoHncZt6XH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4iegFLOhqLsZ"
   },
   "source": [
    "The first axis of the training data array corresponds to the training images, while the remaining dimensions are the x and y axes of the image, and the three colour channels (red, green and blue). We can use matplotlib to examine the images - try using plt.imshow on some of the images in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fZzrYL7PuEkz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aVK0L75fqrQt"
   },
   "source": [
    "Before we start training, we will convert the target labels for the images (y_train and y_test) to use a categorical or 'one-hot' encoding. This replaces a one dimensional integer vector with an array where each column corresponds to a possible value of the integer. All values in a row are zero, except for in the column corresponding to the value we want to represent, which is one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2S2I4W3kvvGj"
   },
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yxv7ev2xrH-S"
   },
   "source": [
    "Try printing out y_train and y_train_cat to see how this has changed the labelling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XBGGAhArSu7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WEDdPjcy_RpR"
   },
   "source": [
    "We also need to normalise the image data, as it is currently stored as integers in the range 0-255. We can use the Keras normalize function to do this:\n",
    "\n",
    "```python\n",
    "x_train = normalize(x_train)\n",
    "x_test = normalize(x_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srLs3UNi0nag"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "doJi_2-Arcc2"
   },
   "source": [
    "Now we can construct a Keras model for a deep neural network to use as a classifier. We will use the Sequential model class, and add layers one by one in order, from input to output.\n",
    "\n",
    "First create an empty model using the Sequential() constructor\n",
    "\n",
    "```\n",
    "model = Sequential()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ikl7AahRrzmq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLztvJVTr28k"
   },
   "source": [
    "To start with, we will ignore the fact that the input is an image and treat it as a large vector of inputs. *This is not a sensible approach!*\n",
    "\n",
    "Keras is able to infer the dimensions and connections between each layer, provided it is given the shape of the inputs. In our data, each data point (image) is a 32x32x3 array of values.\n",
    "\n",
    "```\n",
    "model.add(Flatten(input_shape=(32,32,3)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oT7a7Xx_uOJZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhjWTvmQuPxt"
   },
   "source": [
    "We can then add fully connected (dense) layers of hidden units to the model, by specifying the number of hidden units to use. The activation function to use can also be specified.\n",
    "\n",
    "```\n",
    "model.add(Dense(256,activation='relu'))\n",
    "```\n",
    "\n",
    "Try adding two more dense layers to your model, of decreasing size. If you use too many hidden units training may be slow, try starting with 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ks5cMEUfuvIJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ql6XpfrLuvvB"
   },
   "source": [
    "Finally we need an output layer. This is constructed just as with any other, but we need to specify a sensible activation to use. For binary classification, we could use a sigmoid activation. For multi-class classification, we can use softmax (see lecture 5).\n",
    "\n",
    "```\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "```\n",
    "\n",
    "We need to specify the dimension of the output. Since we have used one-hot encoding for the labels in y_train_cat, we need to have one output for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nnw4VPwEvPml"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QnpFsuv2vQI5"
   },
   "source": [
    "Now we need to compile our model, specifying the optimizer to use, the loss, and any metrics we wish to calcuate. We will use the categorical_crossentropy loss, which is another way of saying the likelihood for a categorical variable.\n",
    "\n",
    "```\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44B2zQ2gvlF1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-hcwZrUFvn6a"
   },
   "source": [
    "Now use\n",
    "\n",
    "```\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "to see the structure of your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p4dSzUJP3QWy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4nT4WZk3Qj9"
   },
   "source": [
    "We can fit the model using the fit method, and specifying the minibatch size and total number of passes over the data (epochs).\n",
    "\n",
    "```\n",
    "model.fit(x_train, y_train_cat, batch_size=32, epochs=10)\n",
    "```\n",
    "\n",
    "You may find when training the performance is quite different between runs. After the training has completed, if the fit() method is called again, training will continue from the weights reached at the end of the previous call to fit().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HWCgepo3hAG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "evxJ87my3E6E"
   },
   "source": [
    "Now we can evaluate our model on the test data:\n",
    "\n",
    "```\n",
    "model.evaluate(x_test,y_test_cat)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FleRJftSvY84"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ABbj7I6Y37hS"
   },
   "source": [
    "Now we will construct a convolutional deep neural network, which is more sensible for working with image data. This uses convolutional layers, that connect each unit to only a subset of the units in the previous layer, but does so with several different sets of weights. More on this next lecture.\n",
    "\n",
    "For a convolutional layer, we specify the depth of the layer, and the number of units in the previous layer to consider.\n",
    "\n",
    "```python\n",
    "conv_model = Sequential()\n",
    "conv_model.add(Conv2D(64,3,input_shape=(32,32,3),activation='relu'))\n",
    "conv_model.add(Conv2D(32,3,activation='relu'))\n",
    "conv_model.add(Conv2D(16,3,activation='relu'))\n",
    "```\n",
    "\n",
    "It is common to then add a final dense fully connected layer:\n",
    "\n",
    "```python\n",
    "conv_model.add(Flatten())\n",
    "conv_model.add(Dense(128,activation='relu'))\n",
    "conv_model.add(Dense(10,activation='softmax'))\n",
    "```\n",
    "\n",
    "Construct and compile this model, and look at the model summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fFxJQwsSNzZJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkiqqfwS4PNf"
   },
   "source": [
    "We can specify the validation data when training, and Keras will calculate the validation accuracy at the end of each epoch:\n",
    "\n",
    "```python\n",
    "conv_model.fit(x_train, y_trainC, batch_size=32, epochs=20, \n",
    "               validation_data=(x_test,y_test_cat))\n",
    "```\n",
    "\n",
    "Try this for the conv_model neural network. You can try changing the sizes of the layers to see how this affects the performance, but you will need to be sure to re-compile the model each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6tWRWTPrJwLH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "saYBhJvGBmda"
   },
   "source": [
    "You should see the training accuracy increase to a very high value, but the validation accuracy peak at a much lower value, or even begin to decrease.\n",
    "\n",
    "Now we can try adding regularisation to see how this improves the training. Try using this model first:\n",
    "\n",
    "```python\n",
    "conv_model_reg = Sequential()\n",
    "conv_model_reg.add(Conv2D(64,3,input_shape=(32,32,3),activation='relu',kernel_regularizer=l2(0.01)))\n",
    "conv_model_reg.add(Conv2D(32,3,activation='relu',kernel_regularizer=l2(0.01)))\n",
    "conv_model_reg.add(Conv2D(16,3,activation='relu',kernel_regularizer=l2(0.01)))\n",
    "conv_model_reg.add(Flatten())\n",
    "conv_model_reg.add(Dense(128,activation='relu',kernel_regularizer=l2(0.01)))\n",
    "conv_model_reg.add(Dense(10,activation='softmax'))\n",
    "```\n",
    "\n",
    "Compile the model, look at the summary, and try fitting it. You might want to explore how changing the regularization parameter changes the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RKMmhIw6GHC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OrVudloU8sJt"
   },
   "source": [
    "## Tensorboard\n",
    "\n",
    "We can visualise the training and validation metrics over training epochs using tensorboard. This can be used in Jupyter notebooks with the tensorboard extension:\n",
    "\n",
    "```python\n",
    "%load_ext tensorboard\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9qp52WNJ8tRC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V0gwGijw8-0q"
   },
   "source": [
    "We can run a fit of the model and log the metrics at each epoch using:\n",
    "\n",
    "```python\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"logs/scalarsConv\")\n",
    "conv_model.fit(x_train, y_train_cat, batch_size=32, epochs=20,\n",
    "               validation_data=(x_test,y_test_cat)),\n",
    "               callbacks=[tensorboard_callback])\n",
    "```\n",
    "\n",
    "Try this for both the un-regularised and regularised models. You should specify different names for the log_dir variable, e.g. \"logs/scalarsConv\", \"logs/scalarsConvReg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bQ935is891cf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2_eSMcDw92xL"
   },
   "source": [
    "Now display the output using tensorboard with:\n",
    "\n",
    "```python\n",
    "%tensorboard --logdir logs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KRvf1s20-BRK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sR4vQ8HG9dax"
   },
   "source": [
    "# Further things to try\n",
    "\n",
    "You could also look at:\n",
    "\n",
    " - Changing the numbers of layers in the convolutional neural network.\n",
    " - Adding L1 regularisation.\n",
    " - Using a Dropout layer to add dropout for the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rAatqtXZ9nlm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DeepLearning-Colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
